{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289aa8cc-a187-4efe-b044-41f029f9d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(filename):\n",
    "    y, sr = librosa.load(filename, duration=3, offset=0.5)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17eedb65-5a13-4971-9b14-fceefa2368fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 21:56:42.969143: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('model/SER_model.h5')  # Replace with the path to your model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6848a19c-7fcd-4ceb-804c-e32c270b76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predict function\n",
    "def predict_emotion(audio_file):\n",
    "    # Extract MFCC features from the audio file\n",
    "    mfcc = extract_mfcc(audio_file)  # Assuming you've defined this function\n",
    "\n",
    "    # Reshape the MFCC features to match the model's input shape\n",
    "    mfcc = mfcc.reshape(1, 40, 1)  # Shape should match (batch_size, num_features, num_timesteps)\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = model.predict(mfcc)\n",
    "\n",
    "    # Get the predicted emotion label\n",
    "    predicted_label = np.argmax(predictions)\n",
    "\n",
    "    if predicted_label==0:\n",
    "        return 'Emotion: Angry'\n",
    "    elif predicted_label==1:\n",
    "        return 'Emotion: Disgust'\n",
    "    elif predicted_label==2:\n",
    "        return 'Emotion: Fear'\n",
    "    elif predicted_label==3:\n",
    "        return 'Emotion: Happy'\n",
    "    elif predicted_label==4:\n",
    "        return 'Emotion: Neutral'\n",
    "    elif predicted_label==5:\n",
    "        return 'Emotion: Pleasant_surprise'\n",
    "    else:\n",
    "        return 'Emotion: Sad'\n",
    "    #return predicted_label  # Return the index of the predicted emotion category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58edf68c-51c5-4897-8a6e-25b28f9af6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b93083-203d-4e83-913b-10126a927d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to record audio and save it to a WAV file\n",
    "def record_audio(file_path, duration=7):\n",
    "    print(\"Recording audio...\")\n",
    "    audio_data = sd.rec(int(duration * 44100), samplerate=44100, channels=1, blocking=True)\n",
    "    wavfile.write(file_path, 44100, audio_data)\n",
    "    print(f\"Audio saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50141aae-41c1-48b7-ac1c-081211ce9468",
   "metadata": {},
   "source": [
    "audio_file_path=\"save_input_audios/new_audio.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98887989-506e-4639-97b2-e85093687b6d",
   "metadata": {},
   "source": [
    "# Record and save audio\n",
    "record_audio(audio_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c6a3a2-0396-4fb7-bc58-a36941e8f7ee",
   "metadata": {},
   "source": [
    "# Play the recorded audio\n",
    "Audio(audio_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d417e5-4f7b-4707-b134-1babd2ce2b5b",
   "metadata": {},
   "source": [
    "#audio_file_path = ''# Replace with the path to your audio file\n",
    "predicted_emotion_index = predict_emotion(audio_file_path)\n",
    "print(predicted_emotion_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb118bf-08b7-4bdc-a4dd-eed869d038d7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
