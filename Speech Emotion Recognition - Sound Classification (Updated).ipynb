{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is Loaded\n"
     ]
    }
   ],
   "source": [
    "paths = []\n",
    "labels = []\n",
    "for dirname, _, filenames in os.walk('TESS_Toronto_emotional_speech_set_data'):\n",
    "    for filename in filenames:\n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        label = filename.split('_')[-1]\n",
    "        label = label.split('.')[0]\n",
    "        labels.append(label.lower())\n",
    "    if len(paths) == 2800:\n",
    "        break\n",
    "print('Dataset is Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TESS_Toronto_emotional_speech_set_data/YAF_disgust/YAF_date_disgust.wav',\n",
       " 'TESS_Toronto_emotional_speech_set_data/YAF_disgust/YAF_rag_disgust.wav',\n",
       " 'TESS_Toronto_emotional_speech_set_data/YAF_disgust/YAF_raise_disgust.wav',\n",
       " 'TESS_Toronto_emotional_speech_set_data/YAF_disgust/YAF_ditch_disgust.wav',\n",
       " 'TESS_Toronto_emotional_speech_set_data/YAF_disgust/YAF_door_disgust.wav']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disgust', 'disgust', 'disgust', 'disgust', 'disgust']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TESS_Toronto_emotional_speech_set_data/YAF_dis...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TESS_Toronto_emotional_speech_set_data/YAF_dis...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TESS_Toronto_emotional_speech_set_data/YAF_dis...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TESS_Toronto_emotional_speech_set_data/YAF_dis...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TESS_Toronto_emotional_speech_set_data/YAF_dis...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              speech    label\n",
       "0  TESS_Toronto_emotional_speech_set_data/YAF_dis...  disgust\n",
       "1  TESS_Toronto_emotional_speech_set_data/YAF_dis...  disgust\n",
       "2  TESS_Toronto_emotional_speech_set_data/YAF_dis...  disgust\n",
       "3  TESS_Toronto_emotional_speech_set_data/YAF_dis...  disgust\n",
       "4  TESS_Toronto_emotional_speech_set_data/YAF_dis...  disgust"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a dataframe\n",
    "df = pd.DataFrame()\n",
    "df['speech'] = paths\n",
    "df['label'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "disgust    400\n",
       "ps         400\n",
       "happy      400\n",
       "sad        400\n",
       "neutral    400\n",
       "fear       400\n",
       "angry      400\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='count', ylabel='label'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGwCAYAAACNeeBZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyK0lEQVR4nO3deVhUdf//8dewj8uAIgoUKiqSmpBLGllogVmWP7W7zRaxTO+yNCqzbNO6NSrT0jbLFrXNNrXFpVxCyxQVxTSNW01CC6VFGHFBkfP7o9v5Nq7oB5xhfD6ua66Lc87nnHm/PXTzuj/nzBmbZVmWAAAAcEr8PF0AAABAdUaYAgAAMECYAgAAMECYAgAAMECYAgAAMECYAgAAMECYAgAAMBDg6QJ8XXl5uX777TfVrl1bNpvN0+UAAIAKsCxLu3btUnR0tPz8jj/3RJiqYr/99ptiYmI8XQYAADgFW7du1dlnn33cMYSpKla7dm1Jf58Mh8Ph4WoAAEBFOJ1OxcTEuP6OHw9hqoodurTncDgIUwAAVDMVuUWHG9ABAAAMEKYAAAAMcJnvNEl+9AP5B9s9XQYAAD4le0xfT5fAzBQAAIAJwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABrwtTXbp0UXp6uiSpcePGeuGFFzxaDwAAwPEEeLqA41mxYoVq1qzp6TIkSXl5eYqNjdXq1at13nnnebocAADgJbw6TEVERHi6BAAAgOPy6GW+3bt3q2/fvqpVq5aioqI0duxYt+3/vMxnWZZGjhyphg0bKjg4WNHR0RoyZIhrbEFBga688krZ7XbFxsbq/fffd9s/Ly9PNptNOTk5rn2Kiopks9mUmZkpSdq5c6duuukmRUREyG63Ky4uTm+//bYkKTY2VpLUpk0b2Ww2denSpUr+TQAAQPXi0ZmpBx54QIsWLdJnn32m+vXr6+GHH9aqVauOehnt008/1fPPP69p06apVatW2r59u9asWePa3rdvX/3xxx/KzMxUYGCg7rvvPhUWFp5UPY899pjWr1+vOXPmqF69etq0aZP27t0rSVq+fLk6dOig+fPnq1WrVgoKCjrqMUpLS1VaWupadjqdJ1UDAACoXjwWpkpKSvTmm2/q3XffVUpKiiRpypQpOvvss486Pj8/X5GRkUpNTVVgYKAaNmyoDh06SJJ++uknzZ8/XytWrFD79u0lSW+88Ybi4uJOqqb8/Hy1adPGdYzGjRu7th265BgeHq7IyMhjHiMjI0NPPPHESb0vAACovjx2mW/z5s3av3+/Onbs6FpXt25dxcfHH3X8tddeq71796pJkyYaMGCAZsyYobKyMklSbm6uAgIC1LZtW9f4Zs2aqU6dOidV05133qlp06bpvPPO07Bhw/T999+fdF/Dhw9XcXGx67V169aTPgYAAKg+vO7RCMcSExOj3NxcvfLKK7Lb7Ro0aJCSk5N14MCBCu3v5/d3q5ZludYdvu8VV1yhX375Rffee69+++03paSkaOjQoSdVZ3BwsBwOh9sLAAD4Lo+FqaZNmyowMFBZWVmudTt37tR///vfY+5jt9vVo0cPTZgwQZmZmVq6dKnWrl2r+Ph4lZWVafXq1a6xmzZt0s6dO13Lhy7TFRQUuNb982b0f45LS0vTu+++qxdeeEGvv/66JLnukTp48OCpNQwAAHySx+6ZqlWrlvr3768HHnhA4eHhql+/vh555BHXDNLhJk+erIMHD6pjx46qUaOG3n33XdntdjVq1Ejh4eFKTU3VwIED9eqrryowMFD333+/7Ha7bDabpL+D2AUXXKCnn35asbGxKiws1KOPPur2Ho8//rjatWunVq1aqbS0VF9++aVatGghSapfv77sdrvmzp2rs88+WyEhIQoNDa3afyQAAOD1PHqZb8yYMbr44ovVo0cPpaam6qKLLlK7du2OOjYsLEyTJk1Sp06dlJCQoPnz5+uLL75QeHi4JGnq1Klq0KCBkpOT1bt3bw0YMEC1a9dWSEiI6xhvvfWWysrK1K5dO6Wnp2vUqFFu7xEUFKThw4crISFBycnJ8vf317Rp0yRJAQEBmjBhgl577TVFR0erZ8+eVfSvAgAAqhOb9c+biHzItm3bFBMTo/nz57s+LegJTqdToaGhShw8Uf7Bdo/VAQCAL8oe07dKjnvo73dxcfEJ73/26iegn4yFCxeqpKRErVu3VkFBgYYNG6bGjRsrOTnZ06UBAAAf5jNh6sCBA3r44Yf1888/q3bt2rrwwgv13nvvKTAw0NOlAQAAH+YzYapbt27q1q2bp8sAAABnmGrznCkAAABvRJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAw4DPfzeftFo/qI4fD4ekyAABAJWNmCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABPQD9Nkh/9QP7Bdk+XAQCAT8ke09fTJTAzBQAAYIIwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwBQAAYIAwJalLly66++67dffddys0NFT16tXTY489JsuyJEmvvPKK4uLiFBISogYNGuiaa6455rFKS0vldDrdXgAAwHcFeLoAbzFlyhT1799fy5cv18qVKzVw4EA1bNhQbdq00ZAhQ/TOO+/owgsv1F9//aVvv/32mMfJyMjQE088cRorBwAAnmSzDk2/nMG6dOmiwsJC/fjjj7LZbJKkhx56SJ9//rlGjRqlW2+9Vdu2bVPt2rVPeKzS0lKVlpa6lp1Op2JiYpQ4eKL8g+1V1gMAAGei7DF9q+S4TqdToaGhKi4ulsPhOO5YLvP9zwUXXOAKUpKUlJSkjRs3KiUlRY0aNVKTJk10yy236L333tOePXuOeZzg4GA5HA63FwAA8F2EqROoVauWVq1apQ8++EBRUVF6/PHHlZiYqKKiIk+XBgAAvABh6n+ysrLclpctW6a4uDj5+/srICBAqampevbZZ/XDDz8oLy9PCxcu9FClAADAm3AD+v/k5+frvvvu07///W+tWrVKL774osaOHasvv/xSP//8s5KTk1WnTh3Nnj1b5eXlio+P93TJAADACxCm/qdv377au3evOnToIH9/f91zzz0aOHCglixZounTp2vkyJHat2+f4uLi9MEHH6hVq1aeLhkAAHgBwtT/BAYG6oUXXtCrr77qtv6iiy5SZmamZ4oCAABej3umAAAADBCmAAAADHCZT+IyHgAAOGXMTAEAABggTAEAABggTAEAABggTAEAABggTAEAABggTAEAABggTAEAABggTAEAABggTAEAABggTAEAABjg62ROk8Wj+sjhcHi6DAAAUMmYmQIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADDA18mcJsmPfiD/YLunywAAwKdkj+nr6RKYmQIAADBBmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADDgtWGqS5cuSk9P93QZAAAAx+W1YQoAAKA6IEwBAAAY8OowVV5ermHDhqlu3bqKjIzUyJEjXdvGjRun1q1bq2bNmoqJidGgQYNUUlLi2j558mSFhYVp5syZiouLU0hIiLp166atW7e6xowcOVLnnXeeXnvtNcXExKhGjRq67rrrVFxcLElavHixAgMDtX37dre60tPTdfHFFx+15tLSUjmdTrcXAADwXV4dpqZMmaKaNWsqKytLzz77rJ588knNmzdPkuTn56cJEyboxx9/1JQpU7Rw4UINGzbMbf89e/Zo9OjRmjp1qpYsWaKioiLdcMMNbmM2bdqkjz76SF988YXmzp2r1atXa9CgQZKk5ORkNWnSRO+8845r/IEDB/Tee+/ptttuO2rNGRkZCg0Ndb1iYmIq858EAAB4Ga8OUwkJCRoxYoTi4uLUt29ftW/fXgsWLJD09+zQJZdcosaNG+vSSy/VqFGj9NFHH7ntf+DAAb300ktKSkpSu3btNGXKFH3//fdavny5a8y+ffs0depUnXfeeUpOTtaLL76oadOmuWaj+vfvr7fffts1/osvvtC+fft03XXXHbXm4cOHq7i42PX650wYAADwPV4fpv4pKipKhYWFkqT58+crJSVFZ511lmrXrq1bbrlFf/75p/bs2eMaHxAQoPPPP9+1fM455ygsLEwbNmxwrWvYsKHOOuss13JSUpLKy8uVm5srSerXr582bdqkZcuWSfr78uF1112nmjVrHrXm4OBgORwOtxcAAPBdXh2mAgMD3ZZtNpvKy8uVl5enq666SgkJCfr000+VnZ2tl19+WZK0f//+Sq2hfv366tGjh95++23t2LFDc+bMOeYlPgAAcOYJ8HQBpyI7O1vl5eUaO3as/Pz+zoOHX+KTpLKyMq1cuVIdOnSQJOXm5qqoqEgtWrRwjcnPz9dvv/2m6OhoSdKyZcvk5+en+Ph415jbb79dffr00dlnn62mTZuqU6dOVdkeAACoRrx6ZupYmjVrpgMHDujFF1/Uzz//rHfeeUcTJ048YlxgYKAGDx6srKwsZWdnq1+/frrgggtc4UqSQkJClJaWpjVr1ujbb7/VkCFDdN111ykyMtI1plu3bnI4HBo1apRuvfXW09IjAACoHqplmEpMTNS4ceP0zDPP6Nxzz9V7772njIyMI8bVqFFDDz74oG688UZ16tRJtWrV0ocffug2plmzZrr66qvVvXt3XXbZZUpISNArr7ziNsbPz0/9+vXTwYMH1bdv3yrtDQAAVC82y7IsTxdRFSZPnqz09HQVFRUdc8zIkSM1c+ZM5eTknPB4/fv31++//67PP//8pOpwOp0KDQ1V4uCJ8g+2n9S+AADg+LLHVM0kx6G/38XFxSf8MFm1vGfqdCouLtbatWv1/vvvn3SQAgAAvo8wdQI9e/bU8uXLdccdd6hr166eLgcAAHgZn73M5y24zAcAQNXxhst81fIGdAAAAG9BmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADBAmAIAADDAd/OdJotH9Tnh4+gBAED1w8wUAACAAcIUAACAAcIUAACAAcIUAACAAcIUAACAAcIUAACAAcIUAACAAcIUAACAAcIUAACAAcIUAACAAb5O5jRJfvQD+QfbPV0GAAA+JXtMX0+XwMwUAACACcIUAACAAcIUAACAAcIUAACAAcIUAACAAcIUAACAAcIUAACAAcIUAACAgQo/tHPChAkVPuiQIUNOqRgAAIDqpsJh6vnnn6/QOJvNRpgCAABnjAqHqS1btlRlHQAAANWS0T1T+/fvV25ursrKyiqrHgAAgGrllMLUnj171L9/f9WoUUOtWrVSfn6+JGnw4MF6+umnK7VAAAAAb3ZKYWr48OFas2aNMjMzFRIS4lqfmpqqDz/8sNKKAwAA8HYVvmfqn2bOnKkPP/xQF1xwgWw2m2t9q1attHnz5korDgAAwNud0szU77//rvr16x+xfvfu3W7hylfZbDbNnDnT02UAAAAvcEphqn379po1a5Zr+VCAeuONN5SUlFQ5lQEAAFQDp3SZ76mnntIVV1yh9evXq6ysTOPHj9f69ev1/fffa9GiRZVdIwAAgNc6pZmpiy66SDk5OSorK1Pr1q319ddfq379+lq6dKnatWtX2TUa++STT9S6dWvZ7XaFh4crNTVVu3fv1ooVK9S1a1fVq1dPoaGh6ty5s1atWuW278aNG5WcnKyQkBC1bNlS8+bN81AXAADAG53SzJQkNW3aVJMmTarMWqpEQUGB+vTpo2effVa9e/fWrl279O2338qyLO3atUtpaWl68cUXZVmWxo4dq+7du2vjxo2qXbu2ysvLdfXVV6tBgwbKyspScXGx0tPTj/t+paWlKi0tdS07nc4q7hAAAHjSKYepgwcPasaMGdqwYYMkqWXLlurZs6cCAk75kFWioKBAZWVluvrqq9WoUSNJUuvWrSVJl156qdvY119/XWFhYVq0aJGuuuoqzZ8/Xz/99JO++uorRUdHS/q/S5zHkpGRoSeeeKKKugEAAN7mlC7z/fjjj2revLnS0tI0Y8YMzZgxQ2lpaYqLi9O6desqu0YjiYmJSklJUevWrXXttddq0qRJ2rlzpyRpx44dGjBggOLi4hQaGiqHw6GSkhLXQ0g3bNigmJgYV5CSdMIb7IcPH67i4mLXa+vWrVXXHAAA8LhTClO33367WrVqpW3btmnVqlVatWqVtm7dqoSEBA0cOLCyazTi7++vefPmac6cOWrZsqVefPFFxcfHa8uWLUpLS1NOTo7Gjx+v77//Xjk5OQoPD9f+/ftP+f2Cg4PlcDjcXgAAwHed0jW5nJwcrVy5UnXq1HGtq1OnjkaPHq3zzz+/0oqrLDabTZ06dVKnTp30+OOPq1GjRpoxY4aWLFmiV155Rd27d5ckbd26VX/88YdrvxYtWmjr1q0qKChQVFSUJGnZsmUe6QEAAHinUwpTzZs3144dO9SqVSu39YWFhWrWrFmlFFZZsrKytGDBAl122WWqX7++srKy9Pvvv6tFixaKi4vTO++8o/bt28vpdOqBBx6Q3W537Zuamuq6nDlmzBg5nU498sgjHuwGAAB4mwpf5nM6na5XRkaGhgwZok8++UTbtm3Ttm3b9Mknnyg9PV3PPPNMVdZ70hwOhxYvXqzu3burefPmevTRRzV27FhdccUVevPNN7Vz5061bdtWt9xyi4YMGeL2ZHc/Pz/NmDFDe/fuVYcOHXT77bdr9OjRHuwGAAB4G5tlWVZFBvr5+bl9Vcyh3Q6t++fywYMHK7vOasvpdCo0NFSJgyfKP9h+4h0AAECFZY/pWyXHPfT3u7i4+IT3P1f4Mt8333xjXBgAAICvqXCY6ty5c1XWAQAAUC0ZPWFzz549ys/PP+JRAgkJCUZFAQAAVBenFKZ+//133XrrrZozZ85Rt3PPFAAAOFOc0kM709PTVVRUpKysLNntds2dO1dTpkxRXFycPv/888quEQAAwGud0szUwoUL9dlnn6l9+/by8/NTo0aN1LVrVzkcDmVkZOjKK6+s7DoBAAC80inNTO3evdv1PKY6dero999/l/T3FwivWrWq8qoDAADwcqcUpuLj45Wbmyvp7y8Sfu211/Trr79q4sSJrq9dAQAAOBOc0mW+e+65RwUFBZKkESNG6PLLL9e7776roKAgTZkypVILBAAA8GanFKZuvvlm18/t2rXTL7/8op9++kkNGzZUvXr1Kq04AAAAb1fhMHXfffdV+KDjxo07pWIAAACqmwqHqdWrV1do3D+/vw8AAMDX8d18AAAABk7p03wAAAD4m9F386HiFo/qI4fD4ekyAABAJWNmCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABfJ3OaJD/6gfyD7Z4uAwAAn5I9pq+nS2BmCgAAwARhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABhCgAAwABh6iQ1btxYL7zwgqfLAAAAXsLnw1SXLl2Unp7u6TIAAICP8vkwVRGWZamsrMzTZQAAgGrIo2GqS5cuGjJkiIYNG6a6desqMjJSI0eOdG0vKirS7bffroiICDkcDl166aVas2aNa3u/fv3Uq1cvt2Omp6erS5curu2LFi3S+PHjZbPZZLPZlJeXp8zMTNlsNs2ZM0ft2rVTcHCwvvvuO23evFk9e/ZUgwYNVKtWLZ1//vmaP3/+afiXAAAA1ZXHZ6amTJmimjVrKisrS88++6yefPJJzZs3T5J07bXXqrCwUHPmzFF2drbatm2rlJQU/fXXXxU69vjx45WUlKQBAwaooKBABQUFiomJcW1/6KGH9PTTT2vDhg1KSEhQSUmJunfvrgULFmj16tW6/PLL1aNHD+Xn51e4n9LSUjmdTrcXAADwXQGeLiAhIUEjRoyQJMXFxemll17SggULZLfbtXz5chUWFio4OFiS9Nxzz2nmzJn65JNPNHDgwBMeOzQ0VEFBQapRo4YiIyOP2P7kk0+qa9euruW6desqMTHRtfyf//xHM2bM0Oeff6677767Qv1kZGToiSeeqNBYAABQ/Xl8ZiohIcFtOSoqSoWFhVqzZo1KSkoUHh6uWrVquV5btmzR5s2bK+W927dv77ZcUlKioUOHqkWLFgoLC1OtWrW0YcOGk5qZGj58uIqLi12vrVu3VkqtAADAO3l8ZiowMNBt2Wazqby8XCUlJYqKilJmZuYR+4SFhUmS/Pz8ZFmW27YDBw5U+L1r1qzptjx06FDNmzdPzz33nJo1aya73a5rrrlG+/fvr/Axg4ODXTNpAADA93k8TB1L27ZttX37dgUEBKhx48ZHHRMREaF169a5rcvJyXELaEFBQTp48GCF3nPJkiXq16+fevfuLenvmaq8vLxTqh8AAJwZPH6Z71hSU1OVlJSkXr166euvv1ZeXp6+//57PfLII1q5cqUk6dJLL9XKlSs1depUbdy4USNGjDgiXDVu3FhZWVnKy8vTH3/8ofLy8mO+Z1xcnKZPn66cnBytWbNGN95443HHAwAAeG2Ystlsmj17tpKTk3XrrbeqefPmuuGGG/TLL7+oQYMGkqRu3brpscce07Bhw3T++edr165d6tu3r9txhg4dKn9/f7Vs2VIRERHHvf9p3LhxqlOnji688EL16NFD3bp1U9u2bau0TwAAUL3ZrMNvOkKlcjqdCg0NVeLgifIPtnu6HAAAfEr2mL4nHnQKDv39Li4ulsPhOO5Yr52ZAgAAqA4IUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYCPF3AmWLxqD5yOByeLgMAAFQyZqYAAAAMEKYAAAAMEKYAAAAMEKYAAAAMEKYAAAAMEKYAAAAMEKYAAAAMEKYAAAAMEKYAAAAM8AT00yT50Q/kH2z3dBkAAPiU7DF9PV0CM1MAAAAmCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGfDJMWZalgQMHqm7durLZbMrJyfF0SQAAwEcFeLqAqjB37lxNnjxZmZmZatKkierVq+fpkgAAgI/yyTC1efNmRUVF6cILL6yy99i/f7+CgoKq7PgAAKB68LnLfP369dPgwYOVn58vm82mxo0bq7y8XBkZGYqNjZXdbldiYqI++eQT1z4HDx5U//79Xdvj4+M1fvz4I47bq1cvjR49WtHR0YqPjz/drQEAAC/kczNT48ePV9OmTfX6669rxYoV8vf3V0ZGht59911NnDhRcXFxWrx4sW6++WZFRESoc+fOKi8v19lnn62PP/5Y4eHh+v777zVw4EBFRUXpuuuucx17wYIFcjgcmjdv3jHfv7S0VKWlpa5lp9NZpf0CAADP8rkwFRoaqtq1a8vf31+RkZEqLS3VU089pfnz5yspKUmS1KRJE3333Xd67bXX1LlzZwUGBuqJJ55wHSM2NlZLly7VRx995BamatasqTfeeOO4l/cyMjLcjgUAAHybz4Wpw23atEl79uxR165d3dbv379fbdq0cS2//PLLeuutt5Sfn6+9e/dq//79Ou+889z2ad269Qnvkxo+fLjuu+8+17LT6VRMTIx5IwAAwCv5fJgqKSmRJM2aNUtnnXWW27bg4GBJ0rRp0zR06FCNHTtWSUlJql27tsaMGaOsrCy38TVr1jzh+wUHB7uOCwAAfJ/Ph6mWLVsqODhY+fn56ty581HHLFmyRBdeeKEGDRrkWrd58+bTVSIAAKjGfD5M1a5dW0OHDtW9996r8vJyXXTRRSouLtaSJUvkcDiUlpamuLg4TZ06VV999ZViY2P1zjvvaMWKFYqNjfV0+QAAwMv5fJiSpP/85z+KiIhQRkaGfv75Z4WFhalt27Z6+OGHJUn//ve/tXr1al1//fWy2Wzq06ePBg0apDlz5ni4cgAA4O1slmVZni7ClzmdToWGhipx8ET5B9s9XQ4AAD4le0zfKjnuob/fxcXFcjgcxx3rcw/tBAAAOJ0IUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYIUwAAAAYCPF3AmWLxqD5yOByeLgMAAFQyZqYAAAAMEKYAAAAMEKYAAAAMEKYAAAAMEKYAAAAMEKYAAAAMEKYAAAAMEKYAAAAMEKYAAAAM8AT00yT50Q/kH2z3dBkAAPiU7DF9PV0CM1MAAAAmCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFMAAAAGCFPHsH//fk+XAAAAqoFqEabmzp2riy66SGFhYQoPD9dVV12lzZs3S5Ly8vJks9k0ffp0XXLJJapRo4YSExO1dOlSt2NMmjRJMTExqlGjhnr37q1x48YpLCzMtX3kyJE677zz9MYbbyg2NlYhISGaOnWqwsPDVVpa6nasXr166ZZbbjlqraWlpXI6nW4vAADgu6pFmNq9e7fuu+8+rVy5UgsWLJCfn5969+6t8vJy15hHHnlEQ4cOVU5Ojpo3b64+ffqorKxMkrRkyRLdcccduueee5STk6OuXbtq9OjRR7zPpk2b9Omnn2r69OnKycnRtddeq4MHD+rzzz93jSksLNSsWbN02223HbXWjIwMhYaGul4xMTGV/K8BAAC8ic2yLMvTRZysP/74QxEREVq7dq1q1aql2NhYvfHGG+rfv78kaf369WrVqpU2bNigc845RzfccINKSkr05Zdfuo5x880368svv1RRUZGkv2emnnrqKf3666+KiIhwjRs0aJDy8vI0e/ZsSdK4ceP08ssva9OmTbLZbEfUVlpa6jaT5XQ6FRMTo8TBE+UfbK+Kfw4AAM5Y2WP6VslxnU6nQkNDVVxcLIfDcdyx1WJmauPGjerTp4+aNGkih8Ohxo0bS5Ly8/NdYxISElw/R0VFSfp7FkmScnNz1aFDB7djHr4sSY0aNXILUpI0YMAAff311/r1118lSZMnT1a/fv2OGqQkKTg4WA6Hw+0FAAB8V4CnC6iIHj16qFGjRpo0aZKio6NVXl6uc8891+0m8cDAQNfPh4LOPy8DVkTNmjWPWNemTRslJiZq6tSpuuyyy/Tjjz9q1qxZp9gJAADwNV4fpv7880/l5uZq0qRJuvjiiyVJ33333UkdIz4+XitWrHBbd/jy8dx+++164YUX9Ouvvyo1NZX7oAAAgIvXX+arU6eOwsPD9frrr2vTpk1auHCh7rvvvpM6xuDBgzV79myNGzdOGzdu1GuvvaY5c+Yc81Ld4W688UZt27ZNkyZNOuaN5wAA4Mzk9WHKz89P06ZNU3Z2ts4991zde++9GjNmzEkdo1OnTpo4caLGjRunxMREzZ07V/fee69CQkIqtH9oaKj+9a9/qVatWurVq9cpdAEAAHxVtfw0X2UYMGCAfvrpJ3377bcVGp+SkqJWrVppwoQJJ/U+hz4NwKf5AACofN7waT6vv2eqsjz33HPq2rWratasqTlz5mjKlCl65ZVXTrjfzp07lZmZqczMzAqNBwAAZ5YzJkwtX75czz77rHbt2qUmTZpowoQJuv3220+4X5s2bbRz504988wzio+PPw2VAgCA6uSMCVMfffTRKe2Xl5dXuYUAAACf4vU3oAMAAHgzwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAIABwhQAAICBM+brZDxt8ag+J/zWaQAAUP0wMwUAAGCAMAUAAGCAMAUAAGCAMAUAAGCAG9CrmGVZkiSn0+nhSgAAQEUd+rt96O/48RCmqtiff/4pSYqJifFwJQAA4GTt2rVLoaGhxx1DmKpidevWlSTl5+ef8GRUd06nUzExMdq6davPPwbiTOpVOrP6pVffRK++qSp7tSxLu3btUnR09AnHEqaqmJ/f37elhYaG+vwv9SEOh4NefdSZ1C+9+iZ69U1V1WtFJ0G4AR0AAMAAYQoAAMAAYaqKBQcHa8SIEQoODvZ0KVWOXn3XmdQvvfomevVN3tKrzarIZ/4AAABwVMxMAQAAGCBMAQAAGCBMAQAAGCBMAQAAGCBMVbGXX35ZjRs3VkhIiDp27Kjly5d7uiRjI0eOlM1mc3udc845ru379u3TXXfdpfDwcNWqVUv/+te/tGPHDg9WXHGLFy9Wjx49FB0dLZvNppkzZ7pttyxLjz/+uKKiomS325WamqqNGze6jfnrr7900003yeFwKCwsTP3791dJSclp7KJiTtRrv379jjjPl19+uduY6tBrRkaGzj//fNWuXVv169dXr169lJub6zamIr+z+fn5uvLKK1WjRg3Vr19fDzzwgMrKyk5nKxVSkX67dOlyxLm944473MZUh35fffVVJSQkuB7YmJSUpDlz5ri2+9J5PVGvvnJOD/f000/LZrMpPT3dtc4rz6uFKjNt2jQrKCjIeuutt6wff/zRGjBggBUWFmbt2LHD06UZGTFihNWqVSuroKDA9fr9999d2++44w4rJibGWrBggbVy5UrrggsusC688EIPVlxxs2fPth555BFr+vTpliRrxowZbtuffvppKzQ01Jo5c6a1Zs0a6//9v/9nxcbGWnv37nWNufzyy63ExERr2bJl1rfffms1a9bM6tOnz2nu5MRO1GtaWpp1+eWXu53nv/76y21Mdei1W7du1ttvv22tW7fOysnJsbp37241bNjQKikpcY050e9sWVmZde6551qpqanW6tWrrdmzZ1v16tWzhg8f7omWjqsi/Xbu3NkaMGCA27ktLi52ba8u/X7++efWrFmzrP/+979Wbm6u9fDDD1uBgYHWunXrLMvyrfN6ol595Zz+0/Lly63GjRtbCQkJ1j333ONa743nlTBVhTp06GDdddddruWDBw9a0dHRVkZGhgerMjdixAgrMTHxqNuKioqswMBA6+OPP3at27BhgyXJWrp06WmqsHIcHjDKy8utyMhIa8yYMa51RUVFVnBwsPXBBx9YlmVZ69evtyRZK1ascI2ZM2eOZbPZrF9//fW01X6yjhWmevbsecx9qmuvhYWFliRr0aJFlmVV7Hd29uzZlp+fn7V9+3bXmFdffdVyOBxWaWnp6W3gJB3er2X9/Yf3n3+cDled+61Tp471xhtv+Px5taz/69WyfO+c7tq1y4qLi7PmzZvn1pu3nlcu81WR/fv3Kzs7W6mpqa51fn5+Sk1N1dKlSz1YWeXYuHGjoqOj1aRJE910003Kz8+XJGVnZ+vAgQNufZ9zzjlq2LBhte97y5Yt2r59u1tvoaGh6tixo6u3pUuXKiwsTO3bt3eNSU1NlZ+fn7Kysk57zaYyMzNVv359xcfH684779Sff/7p2lZdey0uLpb0f19CXpHf2aVLl6p169Zq0KCBa0y3bt3kdDr1448/nsbqT97h/R7y3nvvqV69ejr33HM1fPhw7dmzx7WtOvZ78OBBTZs2Tbt371ZSUpJPn9fDez3El87pXXfdpSuvvNLt/Ene+98rX3RcRf744w8dPHjQ7WRKUoMGDfTTTz95qKrK0bFjR02ePFnx8fEqKCjQE088oYsvvljr1q3T9u3bFRQUpLCwMLd9GjRooO3bt3um4EpyqP6jndND27Zv36769eu7bQ8ICFDdunWrXf+XX365rr76asXGxmrz5s16+OGHdcUVV2jp0qXy9/evlr2Wl5crPT1dnTp10rnnnitJFfqd3b59+1HP+6Ft3upo/UrSjTfeqEaNGik6Olo//PCDHnzwQeXm5mr69OmSqle/a9euVVJSkvbt26datWppxowZatmypXJycnzuvB6rV8m3zum0adO0atUqrVix4oht3vrfK2EKJ+2KK65w/ZyQkKCOHTuqUaNG+uijj2S32z1YGSrTDTfc4Pq5devWSkhIUNOmTZWZmamUlBQPVnbq7rrrLq1bt07fffedp0s5LY7V78CBA10/t27dWlFRUUpJSdHmzZvVtGnT012mkfj4eOXk5Ki4uFiffPKJ0tLStGjRIk+XVSWO1WvLli195pxu3bpV99xzj+bNm6eQkBBPl1NhXOarIvXq1ZO/v/8RnzDYsWOHIiMjPVRV1QgLC1Pz5s21adMmRUZGav/+/SoqKnIb4wt9H6r/eOc0MjJShYWFbtvLysr0119/Vfv+mzRponr16mnTpk2Sql+vd999t7788kt98803Ovvss13rK/I7GxkZedTzfmibNzpWv0fTsWNHSXI7t9Wl36CgIDVr1kzt2rVTRkaGEhMTNX78eJ88r8fq9Wiq6znNzs5WYWGh2rZtq4CAAAUEBGjRokWaMGGCAgIC1KBBA688r4SpKhIUFKR27dppwYIFrnXl5eVasGCB2zVuX1BSUqLNmzcrKipK7dq1U2BgoFvfubm5ys/Pr/Z9x8bGKjIy0q03p9OprKwsV29JSUkqKipSdna2a8zChQtVXl7u+h+36mrbtm36888/FRUVJan69GpZlu6++27NmDFDCxcuVGxsrNv2ivzOJiUlae3atW7hcd68eXI4HK7LLN7iRP0eTU5OjiS5ndvq0u/hysvLVVpa6nPn9WgO9Xo01fWcpqSkaO3atcrJyXG92rdvr5tuusn1s1ee1yq5rR2WZf39aITg4GBr8uTJ1vr1662BAwdaYWFhbp8wqI7uv/9+KzMz09qyZYu1ZMkSKzU11apXr55VWFhoWdbfH1tt2LChtXDhQmvlypVWUlKSlZSU5OGqK2bXrl3W6tWrrdWrV1uSrHHjxlmrV6+2fvnlF8uy/n40QlhYmPXZZ59ZP/zwg9WzZ8+jPhqhTZs2VlZWlvXdd99ZcXFxXve4AMs6fq+7du2yhg4dai1dutTasmWLNX/+fKtt27ZWXFyctW/fPtcxqkOvd955pxUaGmplZma6fWx8z549rjEn+p099FHryy67zMrJybHmzp1rRUREeOXHyk/U76ZNm6wnn3zSWrlypbVlyxbrs88+s5o0aWIlJye7jlFd+n3ooYesRYsWWVu2bLF++OEH66GHHrJsNpv19ddfW5blW+f1eL360jk9msM/qeiN55UwVcVefPFFq2HDhlZQUJDVoUMHa9myZZ4uydj1119vRUVFWUFBQdZZZ51lXX/99damTZtc2/fu3WsNGjTIqlOnjlWjRg2rd+/eVkFBgQcrrrhvvvnGknTEKy0tzbKsvx+P8Nhjj1kNGjSwgoODrZSUFCs3N9ftGH/++afVp08fq1atWpbD4bBuvfVWa9euXR7o5viO1+uePXusyy67zIqIiLACAwOtRo0aWQMGDDji/whUh16P1qMk6+2333aNqcjvbF5ennXFFVdYdrvdqlevnnX//fdbBw4cOM3dnNiJ+s3Pz7eSk5OtunXrWsHBwVazZs2sBx54wO2ZRJZVPfq97bbbrEaNGllBQUFWRESElZKS4gpSluVb5/V4vfrSOT2aw8OUN55Xm2VZVtXMeQEAAPg+7pkCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAAAwQJgCAA/Jy8uTzWZzfSktgOqJMAUAAGCAMAXgjFVeXq5nn31WzZo1U3BwsBo2bKjRo0dLktauXatLL71Udrtd4eHhGjhwoEpKSlz7dunSRenp6W7H69Wrl/r16+dabty4sZ566inddtttql27tho2bKjXX3/dtT02NlaS1KZNG9lsNnXp0qXKegVQdQhTAM5Yw4cP19NPP63HHntM69ev1/vvv68GDRpo9+7d6tatm+rUqaMVK1bo448/1vz583X33Xef9HuMHTtW7du31+rVqzVo0CDdeeedys3NlSQtX75ckjR//nwVFBRo+vTpldofgNMjwNMFAIAn7Nq1S+PHj9dLL72ktLQ0SVLTpk110UUXadKkSdq3b5+mTp2qmjVrSpJeeukl9ejRQ88884waNGhQ4ffp3r27Bg0aJEl68MEH9fzzz+ubb75RfHy8IiIiJEnh4eGKjIys5A4BnC7MTAE4I23YsEGlpaVKSUk56rbExERXkJKkTp06qby83DWrVFEJCQmun202myIjI1VYWHjqhQPwOoQpAGcku91utL+fn58sy3Jbd+DAgSPGBQYGui3bbDaVl5cbvTcA70KYAnBGiouLk91u14IFC47Y1qJFC61Zs0a7d+92rVuyZIn8/PwUHx8vSYqIiFBBQYFr+8GDB7Vu3bqTqiEoKMi1L4DqizAF4IwUEhKiBx98UMOGDdPUqVO1efNmLVu2TG+++aZuuukmhYSEKC0tTevWrdM333yjwYMH65ZbbnHdL3XppZdq1qxZmjVrln766SfdeeedKioqOqka6tevL7vdrrlz52rHjh0qLi6ugk4BVDXCFIAz1mOPPab7779fjz/+uFq0aKHrr79ehYWFqlGjhr766iv99ddfOv/883XNNdcoJSVFL730kmvf2267TWlpaerbt686d+6sJk2a6JJLLjmp9w8ICNCECRP02muvKTo6Wj179qzsFgGcBjbr8Iv+AAAAqDBmpgAAAAwQpgAAAAwQpgAAAAwQpgAAAAwQpgAAAAwQpgAAAAwQpgAAAAwQpgAAAAwQpgAAAAwQpgAAAAwQpgAAAAz8f4mBmLNahpW1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveplot(data, sr, emotion):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(emotion, size=20)\n",
    "    librosa.display.waveplot(data, sr=sr)\n",
    "    plt.show()\n",
    "    \n",
    "def spectogram(data, sr, emotion):\n",
    "    x = librosa.stft(data)\n",
    "    xdb = librosa.amplitude_to_db(abs(x))\n",
    "    plt.figure(figsize=(11,4))\n",
    "    plt.title(emotion, size=20)\n",
    "    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'librosa.display' has no attribute 'waveplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeech\u001b[39m\u001b[38;5;124m'\u001b[39m][df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39memotion])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m data, sampling_rate \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(path)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mwaveplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memotion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m spectogram(data, sampling_rate, emotion)\n\u001b[1;32m      6\u001b[0m Audio(path)\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36mwaveplot\u001b[0;34m(data, sr, emotion)\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(emotion, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaveplot\u001b[49m(data, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'librosa.display' has no attribute 'waveplot'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion = 'fear'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = 'angry'\n",
    "path = np.array(df['speech'][df['label']==emotion])[1]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = 'disgust'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = 'neutral'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = 'sad'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = 'ps'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = 'happy'\n",
    "path = np.array(df['speech'][df['label']==emotion])[0]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "waveplot(data, sampling_rate, emotion)\n",
    "spectogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(filename):\n",
    "    y, sr = librosa.load(filename, duration=3, offset=0.5)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.4636795e+02,  7.3789307e+01,  1.5521719e+00,  4.0626896e+01,\n",
       "       -8.4494524e+00, -2.9341390e+00, -6.6822028e+00, -1.7199314e+01,\n",
       "       -5.6114125e+00, -1.3409514e+01, -7.3893199e+00,  6.8370872e+00,\n",
       "       -1.0458900e+01,  3.2033248e+00, -1.0037700e+00, -5.6148534e+00,\n",
       "        4.2504106e+00, -1.1169560e+00, -9.1154451e+00,  2.1831045e+00,\n",
       "       -7.7419267e+00,  6.4607906e-01, -3.6939952e+00,  3.7297630e-01,\n",
       "       -2.0016887e+00, -1.8217636e+00, -2.7837276e+00,  2.8430927e+00,\n",
       "       -3.0322783e+00,  4.5028725e+00, -8.8743937e-01,  4.2168193e+00,\n",
       "        1.7408412e+00,  3.8251688e+00,  4.3130198e+00,  3.1095667e+00,\n",
       "        3.5192683e+00,  4.1317463e+00,  2.2578502e+00,  2.3055403e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_mfcc(df['speech'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [-446.36795, 73.78931, 1.552172, 40.626896, -8...\n",
       "1       [-383.37564, 108.15568, -17.578175, 15.888096,...\n",
       "2       [-404.0382, 87.21107, 0.48701975, 22.224413, -...\n",
       "3       [-444.80597, 67.52622, -3.808903, 31.318571, -...\n",
       "4       [-430.42755, 118.75985, 6.9652796, 5.204931, -...\n",
       "                              ...                        \n",
       "2795    [-574.7826, 95.66922, 34.85124, 16.821632, 17....\n",
       "2796    [-557.9271, 89.87658, 33.661488, 15.33976, 22....\n",
       "2797    [-527.0877, 115.282486, 26.17239, 7.6268435, 1...\n",
       "2798    [-560.78094, 121.28371, 40.302486, -1.9568781,...\n",
       "2799    [-552.6838, 106.72334, 35.1727, 8.060721, 22.6...\n",
       "Name: speech, Length: 2800, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [x for x in X_mfcc]\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 40, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## input split\n",
    "X = np.expand_dims(X, -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(df[['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 21:52:58.523796: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256)               264192    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305799 (1.17 MB)\n",
      "Trainable params: 305799 (1.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(256, return_sequences=False, input_shape=(40,1)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 10s 231ms/step - loss: 1.1602 - accuracy: 0.5562 - val_loss: 1.3681 - val_accuracy: 0.4036\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 7s 205ms/step - loss: 0.3107 - accuracy: 0.9085 - val_loss: 1.4424 - val_accuracy: 0.5679\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.1750 - accuracy: 0.9473 - val_loss: 1.7502 - val_accuracy: 0.5500\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 7s 202ms/step - loss: 0.1235 - accuracy: 0.9652 - val_loss: 1.7182 - val_accuracy: 0.5804\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.1589 - accuracy: 0.9522 - val_loss: 1.3989 - val_accuracy: 0.6643\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 8s 224ms/step - loss: 0.0961 - accuracy: 0.9723 - val_loss: 2.8090 - val_accuracy: 0.4464\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 7s 206ms/step - loss: 0.1048 - accuracy: 0.9714 - val_loss: 1.7368 - val_accuracy: 0.6411\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 7s 199ms/step - loss: 0.0745 - accuracy: 0.9750 - val_loss: 1.4373 - val_accuracy: 0.6911\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 7s 209ms/step - loss: 0.0917 - accuracy: 0.9754 - val_loss: 1.9769 - val_accuracy: 0.5589\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 7s 214ms/step - loss: 0.0649 - accuracy: 0.9795 - val_loss: 3.3184 - val_accuracy: 0.3696\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 10s 286ms/step - loss: 0.1006 - accuracy: 0.9665 - val_loss: 2.2951 - val_accuracy: 0.5161\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 8s 225ms/step - loss: 0.0765 - accuracy: 0.9786 - val_loss: 2.6084 - val_accuracy: 0.5321\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 7s 208ms/step - loss: 0.0377 - accuracy: 0.9875 - val_loss: 2.2941 - val_accuracy: 0.5732\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 9s 248ms/step - loss: 0.0555 - accuracy: 0.9848 - val_loss: 1.7743 - val_accuracy: 0.6286\n",
      "Epoch 15/50\n",
      " 3/35 [=>............................] - ETA: 7s - loss: 0.1551 - accuracy: 0.9583"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X, y, validation_split=0.2, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best val accuracy: 72.32\n",
    "# use checkpoint to save the best val accuracy model\n",
    "# adjust learning rate for slow convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(50))\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, label='train accuracy')\n",
    "plt.plot(epochs, val_acc, label='val accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, loss, label='train loss')\n",
    "plt.plot(epochs, val_loss, label='val loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('SER_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "SER_model = load_model('SER_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SER_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('model/SER_model.h5')  # Replace with the path to your model file\n",
    "\n",
    "# Define the predict function\n",
    "def predict_emotion(audio_file):\n",
    "    # Extract MFCC features from the audio file\n",
    "    mfcc = extract_mfcc(audio_file)  # Assuming you've defined this function\n",
    "\n",
    "    # Reshape the MFCC features to match the model's input shape\n",
    "    mfcc = mfcc.reshape(1, 40, 1)  # Shape should match (batch_size, num_features, num_timesteps)\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = model.predict(mfcc)\n",
    "\n",
    "    # Get the predicted emotion label\n",
    "    predicted_label = np.argmax(predictions)\n",
    "\n",
    "    if predicted_label==0:\n",
    "        return 'Emotion: Angry'\n",
    "    elif predicted_label==1:\n",
    "        return 'Emotion: Disgust'\n",
    "    elif predicted_label==2:\n",
    "        return 'Emotion: Fear'\n",
    "    elif predicted_label==3:\n",
    "        return 'Emotion: Happy'\n",
    "    elif predicted_label==4:\n",
    "        return 'Emotion: Neutral'\n",
    "    elif predicted_label==5:\n",
    "        return 'Emotion: Pleasant_surprise'\n",
    "    else:\n",
    "        return 'Emotion: Sad'\n",
    "    #return predicted_label  # Return the index of the predicted emotion category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to record audio and save it to a WAV file\n",
    "def record_audio(file_path, duration=5):\n",
    "    print(\"Recording audio...\")\n",
    "    audio_data = sd.rec(int(duration * 44100), samplerate=44100, channels=1, blocking=True)\n",
    "    wavfile.write(file_path, 44100, audio_data)\n",
    "    print(f\"Audio saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record and save audio\n",
    "record_audio(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the recorded audio\n",
    "Audio(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_file_path = ''# Replace with the path to your audio file\n",
    "predicted_emotion_index = predict_emotion(audio_file_path)\n",
    "print(predicted_emotion_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = 'TESS_Toronto_emotional_speech_set_data/OAF_angry/OAF_back_angry.wav'\n",
    "predicted_emotion_index = predict_emotion(audio_file_path)\n",
    "print(predicted_emotion_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('SER_model_updated.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
